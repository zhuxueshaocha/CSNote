# Mysql存储引擎

## InnoDB和MyISAM对比

可以从【事务】【表级锁/行级锁】【存储方式】【热备份/冷备份】几个方面来回答

InnoDB支持事务，可以进行Commit和Rollback；

MyISAM 只支持表级锁，而 InnoDB 还支持行级锁，提高了并发操作的性能；

InnoDB 支持外键；

MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢；

MyISAM 支持压缩表和空间数据索引，InnoDB需要更多的内存和存储；

InnoDB 支持在线热备份

表结构不同： InnoDB 将表结构存储在 .frm 文件中，数据和索引存储在 .idb 文件中。 每个 MyISAM 表格会保存在磁盘的三个文件中，文件名就是表名：.frm：存储表结构.MYD（MYData）：存储数据.MYI（MYIndex）：存储索引

热备份和冷备份

热备份：在数据库运行的情况下备份的方法。优点：可按表或用户备份，备份时数据库仍可使用，可恢复至任一时间点。但是不能出错

冷备份：数据库正常关闭后，将关键性文件复制到另一位置的备份方式。优点：操作简单快速，恢复简单

应用场景

MyISAM 管理非事务表。它提供高速存储和检索（MyISAM强调的是性能，每次查询具有原子性，其执行速度比InnoDB更快），以及全文搜索能力。如果表比较小，或者是只读数据（有大量的SELECT），还是可以使用MyISAM；

InnoDB 支持事务，并发情况下有很好的性能，基本可以替代MyISAM

## 执行一条sql的过程

【先分析mysql的逻辑架构，分为server层和存储引擎层】
其中server层的组件包括连接器，查询缓存，分析器，优化器，执行器，存储引擎层包括各种存储引擎，比如myisam，innodb，memory等

<img width="513" alt="截屏2022-01-24 下午6 16 39" src="https://user-images.githubusercontent.com/98211272/150764380-28342de2-596f-43bc-a0ed-048ae05fcf88.png">

mysql8.0版本之后需要了查询缓存的功能，因为数据失效太过频繁。
<img width="752" alt="截屏2022-02-07 下午10 17 14" src="https://user-images.githubusercontent.com/98211272/152805063-7fe5ff6d-6f47-4a41-8bab-0aa3db7c2607.png">

## mysql的日志系统

### bin log
【提到bin log必须指明它是属于server层的，并且是mysql的逻辑日志】

binlog 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。binlog 是 mysql的逻辑日志，并且由 Server 层进行记录，使用任何存储引擎的 mysql 数据库都会记录 binlog 日志。

逻辑日志：可以简单理解为记录的就是sql语句 。

物理日志：mysql 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 。

binlog 是通过追加的方式进行写入的，可以通过max_binlog_size 参数设置每个 binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。

binlog 的主要使用场景有两个，分别是 主从复制 和 数据恢复 。

主从复制 ：在 Master 端开启 binlog ，然后将 binlog发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致。

数据恢复 ：通过使用 mysqlbinlog 工具来恢复数据。

binlog刷盘时机对于 InnoDB 存储引擎而言，只有在事务提交时才会记录bin log ，此时记录还在内存中，那么 bin log是什么时候刷到磁盘中的呢？

mysql 通过 sync_binlog 参数控制 biglog 的刷盘时机，取值范围是 0-N：

0：不去强制要求，由系统自行判断何时写入磁盘；

1：每次 commit 的时候都要将 binlog 写入磁盘；

N：每N个事务，才会将 binlog 写入磁盘。

从上面可以看出， sync_binlog 最安全的是设置是 1 ，这也是MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。



### redo log

【提到redo log必须指明它是属于存储引擎层的，和bin log配合起来使用】

我们都知道，事务的四大特性里面有一个是 持久性 ，具体来说就是只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态 。redo log是保证事务的持久性的

redo log 包括两部分：一个是内存中的日志缓冲( redo log buffer )，另一个是磁盘上的日志文件( redo logfile)。mysql 每执行一条 DML 语句，先将记录写入 redo log buffer，后续某个时间点再一次性将多个操作记录写到 redo log file。

这种先写日志，再写磁盘 的技术就是 MySQL里经常说到的 WAL(Write-Ahead Logging) 技术。

redo log 实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。

#### redo log与bin log区别

redo log（重做日志）
InnoDB 通过 redo log 实现 crash-safe 能力，即使数据库发生异常重启，已提交的事务都不会丢失。

执行写操作语句时，先把变更内容记录到 redo log 中，并更新内存，语句就执行完成了。
在系统比较空闲的时候，或者 redo log 快写满的时候，再将变更内容应用到磁盘数据页上。
内部实现

redo log 是固定大小的，从头开始写，写到末尾就又回到开头循环写。一般配置为一组 4 个文件，每个 1GB，文件名是ib_logfile+ 数字。
write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。
checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。
write pos 和 checkpoint 之间的是剩余可用空间，用来记录新的操作。
如果 write pos 追上 checkpoint，表示 redo log 已经满了，这时候不能再执行新的写操作，得停下来先擦掉一些记录（应用到磁盘数据页上），把 checkpoint 推进一下。
redo log 的写入机制

事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。当事务中有多个写操作时，每执行一条语句，就改一次内存数据页，写一次 redo log buffer ，因为此时事务尚未提交 ，不能直接写到 redo log 文件里。最后提交事务时，才真正把日志写到 redo log 文件。
由于 redo log 记录的是数据页的变化，因此线程可以共享 redo log buffer。
redo log buffer 里面的内容，可能会在事务还没提交时就先搭便车持久化了，但不是必然每次生成后都直接持久化。
redo log buffer 即使搭便车持久化了，也没有 prepare/ commit 状态的概念，只有该事务提交时写入 redo log 文件时才有状态的概念。
日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是 fsync 持久化到磁盘的速度就慢多了。
write 和 fsync 的时机由参数 innodb_flush_log_at_trx_commit 控制

innodb_flush_log_at_trx_commit=0 ：每次事务提交时都只是把 redo log 留在 redo log buffer 中，由后台线程自动持久化。
innodb_flush_log_at_trx_commit=1 ：每次事务提交时都将 redo log 直接持久化到磁盘，真正实现 crash-safe，最安全。
innodb_flush_log_at_trx_commit=2 ：每次事务提交时都只是把 redo log 写入 page cache，而不 fsync 落盘。
后台线程自动持久化 redo log buffer 的场景

后台线程每秒一次的轮询操作：把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。
redo log buffer 占用的空间即将达到innodb_log_buffer_size 一半的时候，后台线程会主动写盘。
并行的事务提交的时候，顺带将这个事务的 redo log buffer 搭便车持久化到磁盘。
binlog（归档日志）
应用场景

主从复制
误删恢复：让数据库恢复到半个月内任意一秒的状态（定期做整库备份 + 保存最近半个月的所有 binlog）
找到最近的一次全量备份，用这个备份恢复出来一个临时库。
从备份的时间点开始，把 binlog 依次重放到误删表之前的那个时刻。
把表数据从临时库取出来，按需要恢复到线上库去。
binlog 的写入机制

事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中，并清空 binlog cache。
一个事务的 binlog 不能被拆开，不论这个事务多大，也要确保一次性写入，否则在备库执行时就会被当做多个事务分段自行，破坏了原子性。而一个线程只能同时有一个事务在执行，因此系统给每个线程的 binlog cache 分配了一片内存 ，但是所有线程共用同一份 binlog 文件。
参数binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小，超出则需暂存到磁盘。
一个事务的 binlog 日志不会被拆到两个 binlog 文件，即使当前文件写入这条 binlog 之后会超过设置的max_binlog_size值，也会等到这个事务的日志写完再rotate，所以会出现超过配置大小上限的binlog 文件。
write 和 fsync 的时机由参数 sync_binlog 控制

sync_binlog=0：每次提交事务都只 write 就返回，由操作系统决定何时落盘，风险最大。
sync_binlog=1：每次提交事务都会执行 fsync，从而保证 binlog 不会丢失事务，最安全。
sync_binlog=N(100～1000) ：每次提交事务都只 write 就返回，但累积 N 个（组提交）事务时后台会一起 fsync。在出现 IO 瓶颈的场景里，可以提升性能。风险是，如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。





### undo log

【undo log用来保证事务的原子性，而且是实现MVCC的关键】
用来保证事务的原子性，undo log主要记录了数据的逻辑变化，比如一条 INSERT 语句，对应一条DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的 undo log ，这样在发生错误时，就能回滚到事务之前的数据状态。
同时，undo log 也是 MVCC(多版本并发控制)实现的关键。


## 两阶段提交

由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。
仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？
先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。
然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。
先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。
可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案。


![截屏2022-03-03 下午3 44 22](https://user-images.githubusercontent.com/98211272/156519358-2ea269fd-f17d-488b-895a-90f579ebeb18.png)

一个比较形象的例子：

一个完整的交易过程：账本记上 卖一瓶可乐（redo log为 prepare状态），然后收钱放入钱 箱（bin log记录）然后回过头在账本上打个勾（redo log置为commit）表示一笔交易结束。 如果收钱时交易被打断，回过头来整理此次交易，发现只有记账没有收钱，则交易失败，删掉 账本上的记录（回滚）；如果收了钱后被终止，然后回过头发现账本有记录（prepare）而且 钱箱有本次收入（bin log），则继续完善账本（commit），本次交易有效


# 索引

## 什么是索引

索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。
索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。

更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。

## Mysql的几种索引

索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。

1. B+Tree 索引

是大多数 MySQL 存储引擎的默认索引类型。

因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。

因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。

可以指定多个列作为索引列，多个索引列共同组成键。

适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。

InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。
辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

2. 哈希索引

哈希索引能以 O(1) 时间进行查找，但是失去了有序性：

无法用于排序与分组；

只支持精确查找，无法用于部分查找和范围查找。

InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。

3. 全文索引

MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。

查找条件使用 MATCH AGAINST，而不是普通的 WHERE。

全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。

InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。

## B+ Tree 原理

【简单提及一下bst树，avl树，红黑树的不足】

1. 数据结构
B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。

B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。

在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。





2. 操作

进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。

插入删除操作会破坏平衡树的平衡性，因此在进行插入删除操作之后，需要对树进行分裂、合并、旋转等操作来维护平衡性。

3. 与红黑树的比较

红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，这是因为使用 B+ 树访问磁盘数据有更高的性能。

（一）B+ 树有更低的树高

平衡树的树高 O(h)=O(logdN)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多。

（二）磁盘访问原理

操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。

如果数据不在同一个磁盘块上，那么通常需要移动制动手臂进行寻道，而制动手臂因为其物理结构导致了移动效率低下，从而增加磁盘数据读取时间。B+ 树相对于红黑树有更低的树高，进行寻道的次数与树高成正比，在同一个磁盘块上进行访问只需要很短的磁盘旋转时间，所以 B+ 树更适合磁盘数据的读取。

（三）磁盘预读特性

为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。并且可以利用预读特性，相邻的节点也能够被预先载入。

## 索引的分类？

普通索引

唯一索引 UNIQUE：索引列的值必须唯一，但允许有空值；

主键索引 PRIMARY KEY：必须唯一，不允许空值（是一种特殊的唯一索引；MySQL创建主键时默认为聚集索引，但主键也可以是非聚集索引；

单列索引和多列索引/复合索引（Composite）：索引的列数；

覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只需要读取索引而不需要回表读取数据；

聚集（Clustered）索引/非聚集索引：对磁盘上存放数据的物理地址重新组织以使这些数据按照指定规则排序的一种索引（数据的物理排列顺序和索引排列顺序一致）。因此每张表只能创建一个聚集索引（因为要改变物理存储顺序）。优点是查询速度快，因为可以直接按照顺序得到需要数据的物理地址。缺点是进行修改的速度较慢。对于需要经常搜索范围的值很有效。非聚集索引只记录逻辑顺序，并不改变物理顺序；

虚拟索引（Virtual）：模拟索引的存在而不用真正创建一个索引，用于快速测试创建索引对执行计划的影响。没有相关的索引段，不增加存储空间的使用

## 索引的优点和缺点

优点：

大大加快了数据的检索速度；

可以显著减少查询中分组和排序的时间；

通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；

将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）

缺点：

建立和维护索引耗费时间空间，更新索引很慢。

## 在哪些地方适合创建索引？

某列经常作为最大最小值；

经常被查询的字段；

经常用作表连接的字段；

经常出现在ORDER BY/GROUP BY/DISDINCT后面的字段

### 创建索引时需要注意什么？
【创建索引和维护索引需要时间，索引列最好区分度大一些】。

只应建立在小字段上，而不要对大文本或图片建立索引（一页存储的数据越多一次IO操作获取的数据越大效率越高）；

建立索引的字段应该非空，在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用0、一个特殊的值或者一个空串代替NULL；

选择数据密度大（唯一值占总数的百分比很大）的字段作索引

## 哪些情况下索引会失效？

以“%(表示任意0个或多个字符)”开头的LIKE语句；

OR语句前后没有同时使用索引；

数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；

对于多列索引，必须满足 最左匹配原则/最左前缀原则 (最左优先，eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)；

如果MySQL估计全表扫描比索引快，则不使用索引（比如非常小的表）

说明：Mysql8.0的联合索引不受最右匹配选择的限制

## 如何优化数据库？

### SQL 语句的优化

分析慢查询日志：记录了在MySQL中响应时间超过阀值long_query_time的SQL语句，通过日志去找出IO大的SQL以及发现未命中索引的SQL

使用 Explain 进行分析：通过explain命令可以得到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、哪些索引被实际使用、表之间的引用以及被扫描的行数等问题；

应尽量避免在 where 子句中使用!=、<、>操作符或对字段进行null值判断，否则将引擎放弃使用索引而进行全表扫描；

只返回必要的列：最好不要使用 SELECT * 语句；

只返回必要的行：使用 LIMIT 语句来限制返回的数据；

将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用；分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余的查询；减少锁竞争

### 索引的优化

注意会引起索引失效的情况，以及在适合的地方建立索引

### 数据库表结构的优化

设计表时遵循三大范式；

选择合适的数据类型：尽可能不要存储NULL字段；使用简单的数据类型（int, varchar/ text）；

表的水平切分（Sharding）：将同一个表中的记录拆分到多个结构相同的表中（策略：哈希取模；根据ID范围来分）。当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力；

表的垂直切分：将一张表按列切分成多个表。可以将不常用的字段单独放在同一个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切的）放在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，数据维护简单；

### 系统配置的优化

操作系统：增加TCP支持的队列数；

MySQL配置文件优化：缓存池大小和个数设置

### 硬件的优化

磁盘性能：固态硬盘；

CPU：多核且高频；

内存：增大内存

# 事务和锁

## 事务的概念和特性

概念：事务（Transaction）是一个操作序列，不可分割的工作单位，以BEGIN TRANSACTION开始，以ROLLBACK/COMMIT结束

特性（ACID）：

原子性（Atomicity）：逻辑上是不可分割的操作单元，事务的所有操作要么全部提交成功，要么全部失败回滚（用回滚日志实现，反向执行日志中的操作）；

一致性（Consistency）：事务的执行必须使数据库保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的；

隔离性（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的（并发执行的事务之间不能相互影响）；

持久性（Durability）：一旦事务提交成功，对数据的修改是永久性的（用redo来实现）

## 数据库的四种隔离级别？

未提交读（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。会导致脏读、不可重复读、幻读；

提交读（Read Commited）：一个事务只能看见已经提交的事务所作的改变。可避免脏读问题；

可重复读（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（MySQL的默认隔离级别）。可避免不可重复读；

可串行化（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。

## 会出现哪些并发一致性问题？

丢失修改：一个事务对数据进行了修改，在事务提交之前，另一个事务对同一个数据进行了修改，覆盖了之前的修改；

脏读（Dirty Read）：一个事务读取了被另一个事务修改、但未提交（进行了回滚）的数据，造成两个事务得到的数据不一致；

不可重复读（Nonrepeatable Read）：在同一个事务中，某查询操作在一个时间读取某一行数据和之后一个时间读取该行数据，发现数据已经发生修改（针对update操作）；

幻读（Phantom Read）：当同一查询多次执行时，由于其它事务在这个数据范围内执行了插入操作，会导致每次返回不同的结果集（和不可重复读的区别：针对的是一个数据整体/范围；并且针对insert操作）

## 什么是乐观锁和悲观锁？

悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于数据更新比较频繁的场景；

乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于读多写少的场景。乐观锁的实现方式有：加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段；先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新类似于java里面的cas，redis中的watch（）

## 锁的分类

排它锁（Exclusive Lock）/ X锁：事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁；

共享锁（Shared Lock）/ S锁：加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁

意向锁（Intention Locks）：

一个事务在获得某个数据行对象的 S 锁之前，必须先获得整个表的 IS 锁或更强的锁；

一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁；

IS/IX 锁之间都是兼容的；

好处：如果一个事务想要对整个表加X锁，就需要先检测是否有其它事务对该表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检测整个表是否存在IX/IS/X/S锁就行了
锁的作用：用于管理对共享资源的并发访问，保证数据库的完整性和一致性

## 锁的范围

根据加锁范围：MySQL里面的锁可以分为：全局锁、表级锁、行级锁

### 全局锁

对整个数据库实例加锁。MySQL提供加全局读锁的方法：Flush tables with read lock(FTWRL) 这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。

使用场景：

全库逻辑备份。

1 如果在主库备份，在备份期间不能更新，业务停摆

2.如果在从库备份，备份期间不能执行主库同步的binlog。

### 表级锁

MySQL里面表级锁有两种，一种是表锁，一种是元数据锁(meta data lock,MDL)

所以修改global变量，表锁的语法是:lock tables read/write 可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。
lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。对于InnoDB这种支持行锁的引擎，一般不使用locktables命令来控制并发，毕竟锁住整个表的影响面还是太大。

MDL：

不需要显式使用，在访问一个表的时候会被自动加上。

MDL的作用：

保证读写的正确性。在对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。读锁之间不互斥。读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。
MDL会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。

### 行级锁（InnoDB特有的）

innoDB行锁算法分为3种：

Record Lock 单个行记录上的锁

Gap Lock 间隙锁 锁定一个范围，但不包含记录本身

Next-key Lock 相当于Record Lock + Gap Lock

好处：锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高；

坏处：系统开销大（加锁、释放锁、检查锁的状态都需要消耗资源）

### 死锁

1.可以设置超时时间，InnoDB的默认超时时间为50s

2.开启死锁检测，当发生死锁的时候，主动回滚某一个事务

## 什么是三级封锁协议？
【分别解决了丢失更新，脏读和不可重复读的问题】
一级封锁协议：事务在修改数据之前必须先对其加X锁，直到事务结束才释放。可以解决丢失修改问题（两个事务不能同时对一个数据加X锁，避免了修改被覆盖）；

二级封锁协议：在一级的基础上，事务在读取数据之前必须先加S锁，读完后释放。可以解决脏读问题（如果已经有事务在修改数据，就意味着已经加了X锁，此时想要读取数据的事务并不能加S锁，也就无法进行读取，避免了读取脏数据）；

三级封锁协议：在二级的基础上，事务在读取数据之前必须先加S锁，直到事务结束才能释放。可以解决不可重复读问题（避免了在事务结束前其它事务对数据加X锁进行修改，保证了事务期间数据不会被其它事务更新）

## 什么是两段锁协议？

是指所有的事务必须分两个阶段对数据项加锁和解锁。即事务分两个阶段，第一个阶段是获得封锁。事务可以获得任何数据项上的任何类型的锁，但是不能释放；第二阶段是释放封锁，事务可以释放任何数据项上的任何类型的锁，但不能申请。

第一阶段是获得封锁的阶段，称为扩展阶段：其实也就是该阶段可以进入加锁操作，在对任何数据进行读操作之前要申请获得S锁，在进行写操作之前要申请并获得X锁，加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。就是加锁后就不能解锁了。

第二阶段是释放封锁的阶段，称为收缩阶段：当事务释放一个封锁后，事务进入封锁阶段，在该阶段只能进行解锁而不能再进行加锁操作。

## MVCC

即多版本并发控制。MVCC 是一种并发控制的方法。MVCC 在 MySQL InnoDB 中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读

### 当前读

像 select lock in share mode (共享锁), select for update; update; insert; delete (排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁

### 快照读

像不加锁的 select 操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC ,可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本

### MVCC实现原理

MVCC 的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的。

每行记录除了我们自定义的字段外，还有数据库隐式定义的 DB_TRX_ID, DB_ROLL_PTR, DB_ROW_ID 等字段

#### 三大隐式字段

DB_TRX_ID 6byte，最近修改(修改/插入)事务 ID：记录创建这条记录/最后一次修改该记录的事务 ID

DB_ROLL_PTR 7 byte，回滚指针，指向这条记录的上一个版本（存储于 rollback segment 里）

DB_ROW_ID 6 byte，隐含的自增 ID（隐藏主键），如果数据表没有主键，InnoDB 会自动以DB_ROW_ID产生一个聚簇索引

#### undo log [旧版本链]

undo log 实际上就是存在 rollback segment 中旧记录链

#### Read View 【作可见性判断】

什么是 Read View，说白了 Read View 就是事务进行快照读操作的时候生产的读视图 (Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID (当每个事务开启时，都会被分配一个 ID , 这个 ID 是递增的，所以最新的事务，ID 值越大)

所以我们知道 Read View 主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个 Read View 读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。

Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的 DB_TRX_ID（即当前事务 ID ）取出来，与系统当前其他活跃事务的 ID 去对比（由 Read View 维护），如果 DB_TRX_ID 跟 Read View 的属性做了某些比较，不符合可见性，那就通过 DB_ROLL_PTR 回滚指针去取出 Undo Log 中的 DB_TRX_ID 再比较，即遍历链表的 DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的 DB_TRX_ID , 那么这个 DB_TRX_ID 所在的旧记录就是当前事务能看见的最新老版本

### RC , RR 级别下的 InnoDB 快照读有什么不同？
正是 Read View 生成时机的不同，从而造成 RC , RR 级别下快照读的结果的不同

在 RR 级别下的某个事务的对某条记录的第一次快照读会创建一个快照及 Read View, 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个 Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个 Read View，所以对之后的修改不可见；

即 RR 级别下，快照读生成 Read View 时，Read View 会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见

而在 RC 级别下的，事务中，每次快照读都会新生成一个快照和 Read View , 这就是我们在 RC 级别下的事务中可以看到别的事务提交的更新的原因

总之在 RC 隔离级别下，是每个快照读都会生成并获取最新的 Read View；而在 RR 隔离级别下，则是同一个事务中的第一个快照读才会创建 Read View, 之后的快照读获取的都是同一个 Read View。

## 如何解决幻读

在RR的隔离级别下，Innodb使用MVCC和next-key lock解决幻读，MVCC解决的是普通读（快照读）的幻读，next-key lock解决的是当前读情况下的幻读。


<img width="782" alt="截屏2022-02-13 下午3 47 44" src="https://user-images.githubusercontent.com/98211272/153744078-c7952052-f039-4aeb-8465-b805b6bb7ab3.png">

# 其他

## 数据库三大范式

第一范式（1NF，Normal Form）：属性不应该是可分的。举例：如果将“电话”作为一个属性（一列），是不符合1NF的，因为电话这个属性可以分解为家庭电话和移动电话...如果将“移动电话”作为一个属性，就符合1NF；

第二范式 2NF：每个非主属性完全依赖于主属性集（候选键集）；B完全依赖于A，就是说A中的所有属性唯一决定B，属性少了就不能唯一决定，属性多了则有冗余（叫依赖不叫完全依赖）。举例：（学号，课程名）这个主属性集可以唯一决定成绩，但是对于学生姓名这个属性，（学号，课程名）这个属性集就是冗余的，所以学生姓名不完全依赖于（学号，课程名）这一属性集；主属性集/候选码集：某一组属性能够唯一确定其它的属性（主键就是从候选键集中选的一个键），而其子集不能，这样的属性组中的属性就是主属性；不在候选码集中的属性成为非主属性；可以通过分解来满足 2NF：将（学号，课程名，成绩）做成一张表；（学号，学生姓名）做成另一张表，避免大量的数据冗余； 满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；

第三范式 3NF：在 2NF 的基础上，非主属性不传递依赖于主属性 传递依赖：如果C依赖于B，B依赖于A，那么C传递依赖于A；3NF在2NF的基础上，消除了非主属性之间的依赖；比如一个表中，主属性有（学号），非主属性有（姓名，院系，院长名），可以看到院长名这个非主属性依赖于院系，传递依赖于学号。消除的办法是分解。 必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；

## sql语句的连接方式

内连接（Inner Join）：仅将两个表中满足连接条件的行组合起来作为结果集

外连接（Outer Join）

 1. 左连接：左边表的所有数据都有显示出来，右边的表数据只显示共同有的那部分，没有对应的部分补NULL；
 
 2. 右连接：和左连接相反；

全外连接（Full Outer Join）：查询出左表和右表所有数据，但是去除两表的重复数据

交叉连接（Cross Join）：返回两表的笛卡尔积（对于所含数据分别为m、n的表，返回m*n的结果）

## 为什么要使用视图？什么是视图？
为了提高复杂SQL语句的复用性和表操作的安全性，MySQL数据库管理系统提供了视图特性。所谓视图，本质上是一种虚拟表，在物理上是不存在的，其内容与真实的表相似，包含一系列带有名称的列和
行数据。但是，视图并不在数据库中以储存的数据值形式存在。行和列数据来自定义视图的查询所引用基本表，并且在具体引用视图时动态生成。

视图使开发者只关心感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，而不是视图所引用表中的数据，从而提高了数据库中数据的安全性

### 视图有哪些特点？

视图的特点如下:

视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。

视图是由基本表(实表)产生的表(虚表)。

视图的建立和删除不影响基本表。

对视图内容的更新(添加，删除和修改)直接影响基本表。

当视图来自多个基本表时，不允许添加和删除数据。视图的操作包括创建视图，查看视图，删除视图和修改视图。

### 视图的使用场景有哪些？

下面是视图的常见使用场景：

重用SQL语句；

简化复杂的SQL操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；使用表的组成部分而不是整个表；

保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；

更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据

### 视图的优点
1. 查询简单化。视图能简化用户的操作

2. 数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护

逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性
### 视图的缺点
1. 性能。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所
定义，那么，即使是视图的一个简单查询，数据库也把它变成一个复杂的结合体，需要花费一定的
时间。

2. 修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事
实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对
于比较复杂的视图，比较复杂。

## 什么是存储过程？有哪些优缺点？

存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。想要实现相应的功能时，只需要调用这个存储过程就行了（类似于函数，输入具有输出参数）。

优点：

预先编译，而不需要每次运行时编译，提高了数据库执行效率；

封装了一系列操作，对于一些数据交互比较多的操作，相比于单独执行SQL语句，可以减少网络通信量；具有可复用性，减少了数据库开发的工作量；

安全性高，可以让没有权限的用户通过存储过程间接操作数据库；更易于维护

缺点：

可移植性差，存储过程将应用程序绑定到了数据库上；

开发调试复杂：没有好的IDE；

修改复杂，需要重新编译，有时还需要更新程序中的代码以更新调用

## 切分

水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。

当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。

垂直切分

垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。

在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。

### 水平切分的策略和问题

Sharding 策略

哈希取模：hash(key) % N；

范围：可以是 ID 范围也可以是时间范围；

映射表：使用单独的一个数据库来存储映射关系。

Sharding 存在的问题

1. 事务问题

使用分布式事务来解决，比如 XA 接口。

2. 连接

可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。

3. ID 唯一性

使用全局唯一 ID UUID

UUID（Universally Unique Identifier）全局唯一标识符，定义为一个字符串主键，采用32位数字组成，编码采用16进制，定义了在时间和空间都完全惟一的系统信息。
UUID的编码规则：

1）1~8位采用系统时间，在系统时间上精确到毫秒级保证时间上的惟一性；

2）9~16位采用底层的IP地址，在服务器集群中的惟一性；

3）17~24位采用当前对象的HashCode值，在一个内部对象上的惟一性；

4）25~32位采用调用方法的一个随机数，在一个对象内的毫秒级的惟一性。

通过以上4种策略可以保证惟一性。在系统中需要用到随机数的地方都可以考虑采用UUID算法。


为每个分片指定一个 ID 范围

分布式 ID 生成器 (如 Twitter 的 Snowflake 算法) snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号。

## 主从复制，读写分离

主从复制

主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。

binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。

I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。

SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。
<img width="727" alt="截屏2022-01-25 上午11 48 09" src="https://user-images.githubusercontent.com/98211272/150907431-ca0e1cb3-7431-4653-b326-ebbb225b106f.png">

读写分离

主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。

读写分离能提高性能的原因在于：

主从服务器负责各自的读和写，极大程度缓解了锁的争用；

从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；

增加冗余，提高可用性。

# 一些数据类型问题

## varchar与char的区别

char的特点：

char表示定长字符串，长度是固定的；如果插入数据的长度小于char的固定长度时，则用空格填充；
因为长度固定，所以存取速度要比varchar快很多，甚至能快50%，但正因为其长度固定，所以会占据多
余的空间，是空间换时间的做法；

对于char来说， 多能存放的字符个数为255，和编码无关 varchar的特点
varchar表示可变长字符串，长度是可变的；
插入的数据是多长，就按照多长来存储；

varchar在存取方面与char相反，它存取慢，因为长度不固定，但正因如此，不占据多余的空间，是时间换空间的做法；

## FLOAT和DOUBLE的区别是什么？

FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。

DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节



